{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "from scipy import spatial\n",
    "from sklearn import metrics\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, Dot, Reshape, Flatten, Concatenate, Dropout\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.load_model('../models/ru_tg_lenta_vector_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spatial.distance.cosine(np.array(model.get_word_vector('tiger')), np.array(model.get_word_vector('elephant'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "all_data = json.load(open('/Users/ilya-gusev/data/ru_tg_texts.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = sorted(all_data, key=lambda x:x['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in all_data[0::2000]:\n",
    "    print(row['date'])\n",
    "    print(row['text'].replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_host_end = {}\n",
    "\n",
    "left = []\n",
    "texts_left = []\n",
    "right = []\n",
    "texts_right = []\n",
    "y = []\n",
    "\n",
    "def words_to_embed(model, words):\n",
    "    vectors = [model.get_word_vector(w) for w in words]\n",
    "    norm_vectors = [x / np.linalg.norm(x) for x in vectors]\n",
    "    avg_wv = np.mean(norm_vectors, axis=0)\n",
    "    max_wv = np.max(norm_vectors, axis=0)\n",
    "    min_wv = np.min(norm_vectors, axis=0)\n",
    "    return np.concatenate((avg_wv, max_wv, min_wv))\n",
    "\n",
    "for count, row in enumerate(all_data):\n",
    "    if count % 1000 == 0:\n",
    "        print(count)\n",
    "    \n",
    "    host = row['site_name']\n",
    "    text = row['text'].strip().replace('\\n', ' ')\n",
    "    date = row['date']\n",
    "    \n",
    "    words = text.split()\n",
    "    words = [w for w in words if w != '']\n",
    "    if len(words) < 4:\n",
    "        continue\n",
    "    words = words[:300]\n",
    "        \n",
    "    border = len(words) // 2\n",
    "    begin_words = words[:border]\n",
    "    end_words = words[border:]\n",
    "    left_sample = words_to_embed(model, begin_words)\n",
    "    right_sample = words_to_embed(model, end_words)\n",
    "    \n",
    "    left.append(left_sample)\n",
    "    texts_left.append(\" \".join(begin_words))\n",
    "    right.append(right_sample)\n",
    "    texts_right.append(\" \".join(end_words))\n",
    "    y.append(1)\n",
    "    if host in last_host_end:\n",
    "        left.append(left_sample)\n",
    "        texts_left.append(\" \".join(begin_words))\n",
    "        right.append(last_host_end[host][0])\n",
    "        texts_right.append(last_host_end[host][1])\n",
    "        y.append(0)\n",
    "    last_host_end[host] = (right_sample, \" \".join(end_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 30000\n",
    "train_left = left[:-test_size ]\n",
    "test_left = left[-test_size :]\n",
    "train_right = right[:-test_size ]\n",
    "test_right = right[-test_size :]\n",
    "train_y = y[:-test_size ]\n",
    "test_y = y[-test_size:]\n",
    "\n",
    "texts_test_left = texts_left[-test_size:]\n",
    "texts_test_right = texts_right[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(0,len(test_y)):\n",
    "    scores.append(-spatial.distance.cosine(test_left[i], test_right[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(test_y, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_input = Input(shape=(150,), dtype='float32')\n",
    "right_input = Input(shape=(150,), dtype='float32')\n",
    "dense = Dense(50, activation='linear')\n",
    "left_dense = dense(left_input)\n",
    "right_dense = dense(right_input)\n",
    "dot_layer = Dense(1, activation='sigmoid')(Dot(axes=1, normalize=True)([left_dense, right_dense]))\n",
    "nn_model = Model(inputs=[left_input, right_input], output=dot_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "nn_model.fit([np.array(train_left), np.array(train_right)],\n",
    "             np.array(train_y),\n",
    "             batch_size=256,\n",
    "             epochs=100,\n",
    "             callbacks=[es,],\n",
    "             validation_data=([np.array(test_left), np.array(test_right)], np.array(test_y)),\n",
    "             verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = nn_model.predict([np.array(test_left), np.array(test_right)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_scores = [float(pred[i]) for i in range(0,len(pred))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(nn_scores), len(test_y), len(texts_left), len(texts_right))\n",
    "for i in range(0,500):\n",
    "    print(\"===============\")\n",
    "    print(nn_scores[i], test_y[i])\n",
    "    print(texts_test_left[i])\n",
    "    print(\"@@@\")\n",
    "    print(texts_test_right[i])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(test_y, nn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "for _ in range(10000):\n",
    "    i = int(random.random()*len(texts_test_left))\n",
    "    j = int(random.random()*len(texts_test_right))\n",
    "    pred = nn_model.predict([np.array([test_left[i]]), np.array([test_right[j]])])\n",
    "    if float(pred[0]) > 0.9:\n",
    "        print('======')\n",
    "        print(pred)\n",
    "        print(texts_test_left[i])\n",
    "        print(\"@@@\")\n",
    "        print(texts_test_right[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = Model(inputs=[left_input, ], output=left_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texts_test_left[0])\n",
    "print(test_left[:1])\n",
    "print(embedder.predict(np.array(test_left[:1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = dense.get_weights()[0]\n",
    "bias = dense.get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"matrix.txt\", \"w\") as w:\n",
    "    for row_num in range(matrix.shape[1]):\n",
    "        row = []\n",
    "        for col_num in range(matrix.shape[0]):\n",
    "            row.append(float(matrix[col_num][row_num]))\n",
    "        w.write(\",\".join(map(str, row)) + \"\\n\")\n",
    "\n",
    "with open(\"bias.txt\", \"w\") as w:\n",
    "    for value in bias:\n",
    "        w.write(\"{}\\n\".format(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
